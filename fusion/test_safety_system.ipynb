{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas scikit-learn xgboost joblib pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c1ac76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munittest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MagicMock\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprocess_capture\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process_capture\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfusion_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fuse_alerts, display_outputs, trigger_alert, DEFAULT_WEIGHTS\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Mock database collections\u001b[39;00m\n",
      "File \u001b[1;32me:\\Solution_securite_perso\\fusion\\process_capture.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m proj_root \u001b[38;5;241m=\u001b[39m Path(os\u001b[38;5;241m.\u001b[39mgetcwd())\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m      9\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(proj_root))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbehavioral_alerts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mincident_prediction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbehavioral_alerts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreshold_adjustment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbehavioral_alerts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detect_user_anomalies\n",
      "File \u001b[1;32me:\\Solution_securite_perso\\behavioral_alerts\\core\\incident_prediction.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Mock Setup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "from process_capture import process_capture\n",
    "from fusion_core import fuse_alerts, display_outputs, trigger_alert, DEFAULT_WEIGHTS\n",
    "\n",
    "# Mock database collections\n",
    "ts_collection = MagicMock()\n",
    "geo_collection = MagicMock()\n",
    "users_collection = MagicMock()\n",
    "ts_collection.find.return_value = [\n",
    "    {\"user_id\": \"user1\", \"latitude\": 36.8065, \"longitude\": 10.1815, \"timestamp\": datetime.now(), \"hour\": 12}] \n",
    "\"\"\"# Mock model functions\n",
    "def capture_and_store(user_id, lat, lon, ts_collection, geo_collection, users_collection):\n",
    "    return datetime.now()\n",
    "\n",
    "def load_threshold_model(user_id):\n",
    "    return None\n",
    "\n",
    "def predict_threshold(model, features):\n",
    "    return 0.05\n",
    "\n",
    "def detect_user_anomalies(lat, lon, hour, weekday, month, user_id, ts_collection, prob_threshold):\n",
    "    return 0.0, 0.6  # loc_anomaly, time_anomaly\n",
    "\n",
    "def load_incident_model(user_id):\n",
    "    return None, None\n",
    "\n",
    "def predict_incident(model, scaler, loc_anomaly, time_anomaly):\n",
    "    return 0.5\n",
    "\n",
    "def predict_crime_risk(lat, lon):\n",
    "    return 0.7\n",
    "\n",
    "def detect_movement_anomaly(user_id, ts_collection, lat, lon, now):\n",
    "    return 0.8\n",
    "\n",
    "def predict_audio_stress(user_id):\n",
    "    return 0.4\n",
    "\n",
    "def detect_emergency_keyword(user_id):\n",
    "    return 0.0\n",
    "\n",
    "def insert_user_alert(users_collection, user_id, loc_anomaly, time_anomaly, incident_prob, trigger_alert):\n",
    "    print(f\"Stored alert for {user_id}\")\"\"\"\n",
    "#INSTEAD HERE WE NEED TO CALL OUR MODELS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21be9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67e6a1",
   "metadata": {},
   "source": [
    "IMPORTING THE FIRSTMODEL: HIGH RISK LOCATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d51896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadc207c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DBSCAN from version 1.5.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator OPTICS from version 1.5.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#DBSCAN artifacts\n",
    "dbscan       = joblib.load( \"../models/riskyzones/risky_location_model_dbscan.pkl\")\n",
    "cw_dbscan    = joblib.load(\"../models/riskyzones/cluster_weights_dbscan.pkl\")\n",
    "cf_dbscan    = joblib.load(\"../models/riskyzones/cluster_fatalities_dbscan.pkl\")\n",
    "cet_dbscan   = joblib.load(\"../models/riskyzones/cluster_event_types_dbscan.pkl\")\n",
    "\n",
    "#OPTICS artifacts\n",
    "optics       = joblib.load(\"../models/riskyzones/risky_location_model_optics.pkl\")\n",
    "cw_optics    = joblib.load(\"../models/riskyzones/cluster_weights_optics.pkl\")\n",
    "cf_optics    = joblib.load(\"../models/riskyzones/cluster_fatalities_optics.pkl\")\n",
    "cet_optics   = joblib.load(\"../models/riskyzones/cluster_event_types_optics.pkl\")\n",
    "#the coordinate scaler and scaled data\n",
    "scaler = joblib.load(\"../models/riskyzones/scaler__risky_loc.pkl\")\n",
    "X_scaled = joblib.load(\"../models/riskyzones/X_scaled.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e2cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models for user 1(as a prototype user)\n",
    "# 2) Dynamic‐threshold model (RandomForestRegressor)\n",
    "thr_model = joblib.load(\"../models/user1/user1_threshold_model.pkl\")\n",
    "\n",
    "# 3) Incident‐prediction model + scaler\n",
    "inc_model   = joblib.load(\"../models/user1/user1_xgboost_incident_pred.pkl\")\n",
    "inc_scaler  = joblib.load(\"../models/user1/user1_xgboost_incident_pred_scaler.pkl\")\n",
    "behavioral_model = joblib.load(\"../models/user1/user1_optics_behavioral_clust.pkl\")\n",
    "scaler_behavioral = joblib.load(\"../models/user1/user1_scaler_behavioral_clust.pkl\")\n",
    "\n",
    "\n",
    "from behavioral_alerts.core.profiling import detect_user_anomalies, load_profile, build_user_profile\n",
    "from behavioral_alerts.core.threshold_adjustment import load_threshold_model, predict_threshold\n",
    "from behavioral_alerts.core.incident_prediction import load_incident_model, predict_incident\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d1a035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e3db3",
   "metadata": {},
   "source": [
    "IMPORTING KEYWORK DETECTOR : TUNBERT FINETUNED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall torch torchaudio numpy speechbrain -y\n",
    "%pip install torch==2.3.0 torchaudio==2.3.0 numpy==1.26.4 speechbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd203f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip speechbrain transformers pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2744d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e2df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (4.53.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers \n",
    "from transformers import BertForSequenceClassification, BertTokenizer, pipeline\n",
    "from speechbrain.inference.interfaces import foreign_class\n",
    "from pyannote.audio import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47939548",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show speechbrain torch numpy torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfacc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load TunBERT for keyword detection\n",
    "tunbert_model = BertForSequenceClassification.from_pretrained(\"../models/fine_tuned_model_tunBERT\", use_safetensors=True)\n",
    "tunbert_tokenizer = BertTokenizer.from_pretrained(\"../models/fine_tuned_model_tunBERT\")\n",
    "keyword_classifier = pipeline(\"text-classification\", model=tunbert_model, tokenizer=tunbert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cacaacc",
   "metadata": {},
   "source": [
    "LOADING RYTHM ANS TONE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf2f82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'foreign_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHUGGINGFACE_HUB_DISABLE_SYMLINKS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m stress_model \u001b[38;5;241m=\u001b[39m \u001b[43mforeign_class\u001b[49m(\n\u001b[0;32m      7\u001b[0m     source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeechbrain/emotion-recognition-wav2vec2-IEMOCAP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     pymodule_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_interface.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     classname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomEncoderWav2vec2Classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     run_opts\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m tone_pipeline \u001b[38;5;241m=\u001b[39m Pipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote/voice-activity-detection\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_KFbtOyWbpfbTjcoRcyfnZzyWHRharpHTKp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m rhythm_pipeline \u001b[38;5;241m=\u001b[39m Pipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote/speaker-diarization\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_KFbtOyWbpfbTjcoRcyfnZzyWHRharpHTKp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'foreign_class' is not defined"
     ]
    }
   ],
   "source": [
    "# Load SpeechBrain and PyAnnote models\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"HUGGINGFACE_HUB_DISABLE_SYMLINKS\"] = \"1\"\n",
    "\n",
    "stress_model2 = foreign_class(\n",
    "    source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\",\n",
    "    pymodule_file=\"custom_interface.py\",\n",
    "    classname=\"CustomEncoderWav2vec2Classifier\",\n",
    "    run_opts={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    ")\n",
    "stress_model = EncoderClassifier.from_hparams(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", savedir=\"pretrained_models/emotion\")\n",
    "\n",
    "tone_pipeline = Pipeline.from_pretrained(\"pyannote/voice-activity-detection\", use_auth_token=\"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\")\n",
    "rhythm_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d957807",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stress_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_test.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m out_prob, score, index, text_lab \u001b[38;5;241m=\u001b[39m \u001b[43mstress_model\u001b[49m\u001b[38;5;241m.\u001b[39mclassify_file(audio_file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stress_model' is not defined"
     ]
    }
   ],
   "source": [
    "audio_file = \"audio_test.wav\"\n",
    "out_prob, score, index, text_lab = stress_model.classify_file(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e647180a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1070378",
   "metadata": {},
   "source": [
    "LOADING TONE ANALYSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d60f8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from audio_processing import tone_analysis\n",
    "audio_file = \"audio_test.wav\"\n",
    "result = tone_analysis(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0fb1c4",
   "metadata": {},
   "source": [
    "IMPORTING TRANSCRIPTION MODEL : WHISPER IMPORT DONE BUT INFERENCE CRASHING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa905bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c83b205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'whisper' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'whisper'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whisper\n",
      "  Using cached whisper-1.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages (from whisper) (1.17.0)\n",
      "Building wheels for collected packages: whisper\n",
      "  Building wheel for whisper (setup.py): started\n",
      "  Building wheel for whisper (setup.py): finished with status 'done'\n",
      "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41475 sha256=34df246396d29b79f6b2aab02a857efc827a0384945b3c5939d273fe2e514721\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\aa\\7c\\1d\\015619716e2facae6631312503baf3c3220e6a9a3508cb14b6\n",
      "Successfully built whisper\n",
      "Installing collected packages: whisper\n",
      "Successfully installed whisper-1.1.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install whisper\n",
    "import whisper\n",
    "whisper_transcription_model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa32ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\audio-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from audio_processing import transcribe_audio\n",
    "audio_file = \"audio_test.wav\"\n",
    "result = whisper_transcription_model.transcribe(audio_file, language=\"ar\")\n",
    "#resilt = transcribe_audio(audio_file, whisper_transcription_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d12e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q faster-whisper\n",
    "\n",
    "!pip install librosa faster-whisper speechbrain pyannote.audio transformers\n",
    "#from audio import analyze_audio\n",
    "from audio_processing import audio_classification\n",
    "\n",
    "print(audio_classification(\"audio_test.wav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0479d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_processing import transcribe_audio,classify_hate_text, stress_detection, tone_analysis, rhythm_analysis\n",
    "audio = \"audio_test.wav\"\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "transcription = transcribe_audio(audio)\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "gc.collect()\n",
    "stress = stress_detection(audio)\n",
    "tone = tone_analysis(audio)\n",
    "rhythm = rhythm_analysis(audio)\n",
    "hate_speech= classify_hate_text(transcription)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb91b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: Test Scenario 1 - Normal Case\n",
    "print(\"=== Testing Normal Case ===\")\n",
    "result = process_capture(\"user123\", 40.7128, -74.0060, ts_collection, geo_collection, users_collection)\n",
    "print(\"Result:\", result)\n",
    "\n",
    "# Cell 3: Test Scenario 2 - High-Risk Case\n",
    "print(\"\\n=== Testing High-Risk Case ===\")\n",
    "def detect_emergency_keyword(user_id):  # Override for high-risk\n",
    "    return 1.0\n",
    "def predict_audio_stress(user_id):  # Override for high-risk\n",
    "    return 0.9\n",
    "result = process_capture(\"user123\", 40.7128, -74.0060, ts_collection, geo_collection, users_collection)\n",
    "print(\"High-Risk Result:\", result)\n",
    "\n",
    "# Cell 4: Test Scenario 3 - Missing Data\n",
    "print(\"\\n=== Testing Missing Data ===\")\n",
    "def predict_crime_risk(lat, lon):  # Simulate missing data\n",
    "    return 0.0\n",
    "def detect_movement_anomaly(user_id, ts_collection, lat, lon, now):\n",
    "    return 0.0\n",
    "result = process_capture(\"user123\", 40.7128, -74.0060, ts_collection, geo_collection, users_collection)\n",
    "print(\"Missing Data Result:\", result)\n",
    "\n",
    "# Cell 5: Test Scenario 4 - Error Case\n",
    "print(\"\\n=== Testing Error Case ===\") \n",
    "def capture_and_store(user_id, lat, lon, ts_collection, geo_collection, users_collection):\n",
    "    raise Exception(\"Database connection failed\")\n",
    "result = process_capture(\"user123\", 40.7128, -74.0060, ts_collection, geo_collection, users_collection)\n",
    "print(\"Error Case Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26766453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Test Scenario 5 - Low-Risk Case\n",
    "print(\"\\n=== Testing Low-Risk Case ===\")\n",
    "def predict_crime_risk(lat, lon):\n",
    "    return 0.1\n",
    "def detect_movement_anomaly(user_id, ts_collection, lat, lon, now):\n",
    "    return 0.1\n",
    "def predict_audio_stress(user_id):\n",
    "    return 0.1\n",
    "def detect_emergency_keyword(user_id):\n",
    "    return 0.0\n",
    "def detect_user_anomalies(lat, lon, hour, weekday, month, user_id, ts_collection, prob_threshold):\n",
    "    return 0.0, 0.1\n",
    "def predict_incident(model, scaler, loc_anomaly, time_anomaly):\n",
    "    return 0.1\n",
    "result = process_capture(\"user123\", 40.7128, -74.0060, ts_collection, geo_collection, users_collection)\n",
    "print(\"Low-Risk Result:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
